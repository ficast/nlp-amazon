{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY1uLLfIfWun",
    "tags": []
   },
   "source": [
    "## **Step 1: Importing dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cZqrIhfCfuJJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab import drive, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CzH3I7jifv6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ficast/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 09:45:20.899083: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 09:45:21.273763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 5776 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from keras.utils.vis_utils import plot_model\n",
    "print(tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SJhklSJhJm5"
   },
   "source": [
    "## **Step 2: Data preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICVbkzIJ5Q3i"
   },
   "source": [
    "### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42102,
     "status": "ok",
     "timestamp": 1650262035627,
     "user": {
      "displayName": "Filipe de Castro",
      "userId": "11069743125654728085"
     },
     "user_tz": -60
    },
    "id": "EBv855ckhA5Y",
    "outputId": "839c6435-6fee-46c0-b3aa-7d53f1e214ea"
   },
   "outputs": [],
   "source": [
    "# Just required for run it in google colab\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NNkdwusgiYa_"
   },
   "outputs": [],
   "source": [
    "cols= [\"text\"]\n",
    "# path = \"/content/drive/MyDrive/projeto/Projeto II - BDI Uniasselvi/Dataset AMAZON/amazon_train.ft.txt\"\n",
    "path = \"./amazon.ft.txt\"\n",
    "\n",
    "f = open(path, encoding=\"latin\")\n",
    "\n",
    "data = []\n",
    "for line in f:\n",
    "    data_line = [line[9], line[11:]]\n",
    "    data.append(data_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1650262044458,
     "user": {
      "displayName": "Filipe de Castro",
      "userId": "11069743125654728085"
     },
     "user_tz": -60
    },
    "id": "caoL4ivgnneV",
    "outputId": "1cfcc34a-cdea-4e7d-fb6c-612a51379331"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>DVD Player crapped out after one year: I also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Incorrect Disc: I love the style of this, but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0     2  Great CD: My lovely Pat has one of the GREAT v...\n",
       "1     2  One of the best game music soundtracks - for a...\n",
       "2     1  Batteries died within a year ...: I bought thi...\n",
       "3     2  works fine, but Maha Energy is better: Check o...\n",
       "4     2  Great for the non-audiophile: Reviewed quite a...\n",
       "5     1  DVD Player crapped out after one year: I also ...\n",
       "6     1  Incorrect Disc: I love the style of this, but ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "df.head(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-vAdvNK5XZA"
   },
   "source": [
    "### Cleaning and preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1650262044459,
     "user": {
      "displayName": "Filipe de Castro",
      "userId": "11069743125654728085"
     },
     "user_tz": -60
    },
    "id": "2ac8Nhla04Tg",
    "outputId": "637b6916-3197-442c-fc2c-9c342352bb66"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DVD Player crapped out after one year: I also ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Incorrect Disc: I love the style of this, but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Great CD: My lovely Pat has one of the GREAT v...      1\n",
       "1  One of the best game music soundtracks - for a...      1\n",
       "2  Batteries died within a year ...: I bought thi...      0\n",
       "3  works fine, but Maha Energy is better: Check o...      1\n",
       "4  Great for the non-audiophile: Reviewed quite a...      1\n",
       "5  DVD Player crapped out after one year: I also ...      0\n",
       "6  Incorrect Disc: I love the style of this, but ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = np.where(df['label'] == \"2\", 1, 0)\n",
    "df = df[['text', 'label']]\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650262044460,
     "user": {
      "displayName": "Filipe de Castro",
      "userId": "11069743125654728085"
     },
     "user_tz": -60
    },
    "id": "hqUgZ1ak7-Mm",
    "outputId": "883cb8c8-894c-456c-fb65-1aa7ebea60ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels = df.label.values\n",
    "set(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-d3ukNMT4fdW"
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "  # text = BeautifulSoup(text).get_text()\n",
    "  text = re.sub(r\"@[A-Za-z0-9]+\", \" \", text)\n",
    "  text = re.sub(r\"https?://[A-Za-z0-9./]+\", \" \", text)\n",
    "  text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "  text = re.sub(r\" +\", \" \", text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JqIYeGWz5uRl"
   },
   "outputs": [],
   "source": [
    "data_clean = [clean(line) for line in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1650262290438,
     "user": {
      "displayName": "Filipe de Castro",
      "userId": "11069743125654728085"
     },
     "user_tz": -60
    },
    "id": "W73dKrnz7Raj",
    "outputId": "001e096e-63a7-49cf-df26-08a9d5c94daa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great Read Suspenseful When I first started reading the book I kept putting it down it just wasn t grabbing my attention but once I got further into the book my curiosity got the best of me I couldn t put the book down I could not believe that a woman would do the things that she did Adrian Jenkins was confused and deceitful All hell does break loose Gregory s relationship with his mother was sad I understand her point for leaving but at the same time it was selfish It not only destroyed Gregory but it also destroyed his little sister I am definately looking forward to her next book '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[1093]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpayXlkCQ1e-"
   },
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3gsfR6z3QpoZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_noyJwlMRz1L"
   },
   "outputs": [],
   "source": [
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cmclDbAzR6Nt"
   },
   "outputs": [],
   "source": [
    "# Tokenize our training data\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(data_clean)\n",
    "\n",
    "# Get our training data word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Encode training data sentences into sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(data_clean)\n",
    "\n",
    "# Get max training sequence length\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "# Pad the training sequences\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32  83  24 ...   0   0   0]\n",
      " [ 27   8   2 ...   0   0   0]\n",
      " [783   1 599 ...   0   0   0]\n",
      " ...\n",
      " [  1   1   1 ...   0   0   0]\n",
      " [  1 120   1 ...   0   0   0]\n",
      " [  1  21   1 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Elx9QqiwTrUi"
   },
   "source": [
    "### Split train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AP-spDmhSGUj"
   },
   "outputs": [],
   "source": [
    "size = len(train_padded)\n",
    "test_idx = np.random.randint(0, size, round(size/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yETq9tAiUsdi"
   },
   "outputs": [],
   "source": [
    "test_inputs = train_padded[test_idx]\n",
    "test_labels = data_labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pXuMhVAAXeXg"
   },
   "outputs": [],
   "source": [
    "train_inputs = np.delete(train_padded, test_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vDoNTU66Y9oD"
   },
   "outputs": [],
   "source": [
    "train_labels = np.delete(data_labels, test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B01Pl6yiZUQ_"
   },
   "source": [
    "## **Step 3: Building the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Jj7k912FZTV1"
   },
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "  def __init__(self, \n",
    "               vocab_size, \n",
    "               emb_dim=128, \n",
    "               nb_filters=50, \n",
    "               FFN_units=512,\n",
    "               nb_classes=2,\n",
    "               dropout_rate=0.1,\n",
    "               training=False,\n",
    "               name=\"dcnn\"):\n",
    "    super(DCNN, self).__init__(name=name)\n",
    "\n",
    "    self.embeding = layers.Embedding(vocab_size, emb_dim)\n",
    "\n",
    "    self.bigram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=2,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    \n",
    "    self.pool_l = layers.GlobalMaxPool1D()\n",
    "\n",
    "    self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=3,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    \n",
    "    self.pool_2 = layers.GlobalMaxPool1D()\n",
    "\n",
    "    self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                kernel_size=4,\n",
    "                                padding=\"valid\",\n",
    "                                activation=\"relu\")\n",
    "    \n",
    "    self.pool_3 = layers.GlobalMaxPool1D()\n",
    "\n",
    "    self.dense_l = layers.Dense(units=FFN_units, \n",
    "                                activation=\"relu\")\n",
    "\n",
    "    self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "\n",
    "    if nb_classes == 2:\n",
    "      self.last_dense = layers.Dense(units=1, \n",
    "                                     activation=\"sigmoid\")\n",
    "    else:\n",
    "      self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                     activation=\"softmax\")\n",
    "  def call(self, inputs, training):\n",
    "    x = self.embeding(inputs)\n",
    "    x_1 = self.bigram(x)\n",
    "    x_1 = self.pool_l(x_1)\n",
    "    x_2 = self.trigram(x)\n",
    "    x_2 = self.pool_l(x_2)\n",
    "    x_3 = self.trigram(x)\n",
    "    x_3 = self.pool_l(x_3)\n",
    "\n",
    "    merged = tf.concat([x_1, x_2, x_3], axis=-1)\n",
    "    merged = self.dense_l(merged)\n",
    "    merged = self.dropout(merged, training)\n",
    "    output = self.last_dense(merged)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx_GMdnUdDWS"
   },
   "source": [
    "## **Stpe 4: Training Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTt0dfPoeMYA"
   },
   "source": [
    "### Param config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zzYJHNCac1-C"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = num_words\n",
    "\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = len(set(train_labels))\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TG3vYMPLeGDt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 09:47:23.346476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5776 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = DCNN(\n",
    "    vocab_size=VOCAB_SIZE, \n",
    "    emb_dim=EMB_DIM, \n",
    "    nb_filters=EMB_DIM, \n",
    "    FFN_units=FFN_UNITS,\n",
    "    nb_classes=NB_CLASSES,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqWnKiVMeV19"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pcZ1USiGe9NR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if NB_CLASSES == 2:\n",
    "  model.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"accuracy\"])\n",
    "else:\n",
    "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "YW_mAcoFf0LO"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/checkpoint\"\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print(\"Checkpoint looaded from {}\".format(ckpt_manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDV7iWVrgNHX",
    "outputId": "95d86caf-1e10-47fb-fdf0-a76607e8cab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 09:47:23.456042: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1305502020 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 09:47:25.617062: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n",
      "2022-07-16 09:47:26.443332: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-07-16 09:47:27.423214: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40961/40961 [==============================] - 535s 13ms/step - loss: 0.2318 - accuracy: 0.9061\n",
      "Epoch 2/8\n",
      "40961/40961 [==============================] - 370s 9ms/step - loss: 0.2026 - accuracy: 0.9212\n",
      "Epoch 3/8\n",
      "40961/40961 [==============================] - 336s 8ms/step - loss: 0.1910 - accuracy: 0.9269\n",
      "Epoch 4/8\n",
      "40961/40961 [==============================] - 338s 8ms/step - loss: 0.1828 - accuracy: 0.9306\n",
      "Epoch 5/8\n",
      "40961/40961 [==============================] - 341s 8ms/step - loss: 0.1750 - accuracy: 0.9339\n",
      "Epoch 6/8\n",
      "40961/40961 [==============================] - 328s 8ms/step - loss: 0.1682 - accuracy: 0.9366\n",
      "Epoch 7/8\n",
      "40961/40961 [==============================] - 334s 8ms/step - loss: 0.1620 - accuracy: 0.9389\n",
      "Epoch 8/8\n",
      "40961/40961 [==============================] - 337s 8ms/step - loss: 0.1566 - accuracy: 0.9408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_inputs,\n",
    "                    train_labels,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NB_EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dcnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  200000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             multiple                  80200     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  multiple                 0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  120200    \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  multiple                 0 (unused)\n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  multiple                 0 (unused)\n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  153856    \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 554,513\n",
      "Trainable params: 554,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mplot_model(loaded_model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_plot.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(loaded_model, to_file=\"model_plot.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WblHNYjehLa2"
   },
   "source": [
    "## **Step 5: Model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4527/4527 - 16s - loss: 0.1983 - accuracy: 0.9250 - 16s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9249609708786011\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(list_of_sequences):\n",
    "    sentences = tokenizer.texts_to_sequences(list_of_sequences)\n",
    "    predict_padded = pad_sequences(sentences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "    for i in model.predict(predict_padded):\n",
    "        print([i, \"Positive\" if i > 0.5 else \"Negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.], dtype=float32), 'Positive']\n",
      "[array([0.28406608], dtype=float32), 'Negative']\n",
      "[array([0.9994722], dtype=float32), 'Positive']\n",
      "[array([0.9879224], dtype=float32), 'Positive']\n"
     ]
    }
   ],
   "source": [
    "predict([\"I love this\", \n",
    "         \"I can buy a new one of this every year\", \n",
    "         \"Definitely a good choice\",\n",
    "         \"I wanna more this is awesome I would like to have bought it earlier\",\n",
    "         ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.02223525], dtype=float32), 'Negative']\n",
      "[array([0.98893994], dtype=float32), 'Positive']\n",
      "[array([0.01104098], dtype=float32), 'Negative']\n",
      "[array([0.0161139], dtype=float32), 'Negative']\n"
     ]
    }
   ],
   "source": [
    "predict([\"I dont like this book, seems very silly\", \n",
    "         \"I cant recommend this brand again\",\n",
    "         \"Not sure if this is a good choice for you, for me its absolutely useless\",\n",
    "         \"This? Just for my haters. Its impossible to make this works. I guess its the worst game Ive bought in my life\"\n",
    "         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.pooling.GlobalMaxPooling1D object at 0x7f70438ab3a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.Conv1D object at 0x7f70438abca0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.pooling.GlobalMaxPooling1D object at 0x7f70438aba30>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: amazon_nlp/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"amazon_nlp\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RASCUNHO_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
